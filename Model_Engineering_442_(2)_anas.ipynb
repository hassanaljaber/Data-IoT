{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassanaljaber/Data-IoT/blob/main/Model_Engineering_442_(2)_anas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da645ec0",
      "metadata": {
        "id": "da645ec0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "YOUR TASKS:\n",
        "\n",
        "1. SPECIFY THE URL OR PATH TO YOUR DATA, REMEMBER - YOU FIRST HAVE TO DOWNLOAD IT.\n",
        "2. CLICK RUN ALL OR RESTART AND RUN ALL BUTTON TO RUN THE CODE. THIS CODE RUNS IN A CHRONOLOGICAL MANNER - THE TOP BLOCKS MUST PRECEED THE BOTTOM ONES,\n",
        "                                                                                                            i.e. don't run stuff from the bottom first, otherwise the code won't work properly.\n",
        "3. NEAR THE END OF THE CODE, YOU WILL SEE YOUR EPOCH METRICS, AS I STATED IN CLASS, YOU WANT THE ACCURACY TO APPROACH 100% =1.0 AND THE LOSS TO APPROACH 0\n",
        "4. IN CASE IF YOUR MODEL IS STRUGGLING TO REACH THESE RESULTS AND IS INSTEAD STUCK AT A LOW ACCURACY, NAVIGATE TO THE BLOCK OF CODE WITH HYPERPARAMETERS AND CHANGE THESE NUMBERS,\n",
        "THEN, TRY RUNNING THE CODE AGAIN AND SEE HOW YOUR MODEL IS PERFORMING; REPEAT UNTIL YOU REACH A PLAUSIBLE RESULT (ONE THAT IS BETTER THAN A COIN TOSS IN TERMS OF PREDICTION ACCURACY IN THE WORST CASE)\n",
        "5. SAVE YOUR RESULTS => THE CODE INCLUDES A BLOCK WHICH WILL SAVE YOUR MODEL TO A .h5 FILE,\n",
        " - KEEP THE OUTPUTS OF THIS NOTEBOOK AS WELL, YOU WILL WANT TO DEMONSTRATE HOW THE TRAINING PROCESS WENT.\n",
        " - BE MINDFUL OF THE TIME YOU HAVE IF YOU CHOOSE TO USE GOOGLE COLLABORATORY INSTEAD OF YOUR OWN MACHINE AS THEIR VMs ONLY OFFER YOU A COUPLE OF HOURS OF USAGE.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd77aa5b",
      "metadata": {
        "id": "dd77aa5b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f16df2f1",
      "metadata": {
        "id": "f16df2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e79cf5-fa73-4823-e342-0ecbb370d126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e3c3dbfd9106>:10: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  data.iloc[:, -1] = label_encoder.fit_transform(data.iloc[:, -1])\n"
          ]
        }
      ],
      "source": [
        "# Function to read the data\n",
        "def read_data(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "\n",
        "    # Extract features\n",
        "    features = data.iloc[:,1 :-1].values\n",
        "\n",
        "    # Extract and encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    data.iloc[:, -1] = label_encoder.fit_transform(data.iloc[:, -1])\n",
        "    labels = data.iloc[:, -1].values\n",
        "\n",
        "    return features, labels\n",
        "# Read the data\n",
        "data_url = \"https://raw.githubusercontent.com/hassanaljaber/Data-IoT/main/data_anas.csv\" # enter your data URL or PATH here in enclosed in \" \" IF YOUR NOTEBOOK IS IN THE SAME FOLDER AS data.csv, which is your data you downloaded, then this will run as it is.\n",
        "                    # otherwise, you have to specify a different path or url\n",
        "x, y = read_data(data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3eb86201",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eb86201",
        "outputId": "a789503a-d3fe-4d5d-907e-6db887343b36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80628, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x.shape ### IN THE FOLLOWING PARTS OF THE CODE, MAKE SURE THAT EVERYTING IS LOADED CORRECTLY, YOU SHOULD HAVE A DATASET WITH 22 CLASSES, (n-rows, 6 columns, later another dimension will be added here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6b640bf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b640bf8",
        "outputId": "6d82a98e-144e-43b0-eb48-20690aa8ccf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80628,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9650592c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9650592c",
        "outputId": "d6c16bdd-84bd-41b7-d3d7-21b9baf38282"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "np.unique(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0edc69b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0edc69b6",
        "outputId": "5516c77b-cfba-40e8-be5f-1d92f7c2c535"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([86.706818, 29.800388, 17.446753,  0.725778,  1.105902,  0.345016])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b4eec323",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4eec323",
        "outputId": "28de56d3-c4b7-41ce-a267-62422e6924ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y[0] # these were sample rows from the data for your to inspect, you should see a 6 by 1 vector above and a single value here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9db6440b",
      "metadata": {
        "id": "9db6440b"
      },
      "outputs": [],
      "source": [
        "# Split the data into training, validation, and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0b135163",
      "metadata": {
        "id": "0b135163"
      },
      "outputs": [],
      "source": [
        "# Reshape the data\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "936243fe",
      "metadata": {
        "id": "936243fe"
      },
      "outputs": [],
      "source": [
        "# Determine the input shape and number of classes\n",
        "input_shape = (x_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4cb2989e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cb2989e",
        "outputId": "283fff1d-79df-42d7-eeda-1eca670333a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "num_classes # must have 22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "26c6890e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26c6890e",
        "outputId": "0eabd1aa-c9eb-426f-a7b8-e0f20b34fa00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "859aa647",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "859aa647",
        "outputId": "a0f1f8b7-c01d-4737-839c-25880a6c090a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58052, 6, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "eab565dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eab565dd",
        "outputId": "2cef9b98-a3f1-4c2d-fcab-eb194098629c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58052,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ab950213",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab950213",
        "outputId": "eaa4fe99-cd3f-4acd-d719-5839bc018504"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[101.675934],\n",
              "       [ -8.666521],\n",
              "       [132.177704],\n",
              "       [ -0.228124],\n",
              "       [  1.419092],\n",
              "       [  0.640944]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7f11432f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f11432f",
        "outputId": "dcd1be9a-ebd8-46e9-a198-e8e7648267d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cd51204b",
      "metadata": {
        "id": "cd51204b"
      },
      "outputs": [],
      "source": [
        "# Transformer Encoder function with dropout and L2 regularization\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.1, l2_reg=0.01):\n",
        "\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed-forward network with dropout and L2 regularization\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(inputs.shape[-1], activation = 'softmax')(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return x + res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9df843aa",
      "metadata": {
        "id": "9df843aa"
      },
      "outputs": [],
      "source": [
        "# Transformer Decoder function\n",
        "def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0.1, l2_reg=0.01):\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(res, enc_outputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = x + res\n",
        "\n",
        "    # Feed-forward network\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    '''\n",
        "    YOU MAY WANT TO ADD OR REMOVE THESE TWO LINES HERE PRECISELY IN THIS PART OF THE CODE, PAY ATTENTION TO THE INDENTATION, PYTHON REQUIRES CONSISTENCY IN ORDER FOR THE CODE TO RUN CORRECTLY\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    '''\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(inputs.shape[-1], activation = 'softmax')(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return x + res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d9851305",
      "metadata": {
        "id": "d9851305"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0, l2_reg=0):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Encoder\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout, l2_reg)\n",
        "\n",
        "\n",
        "    # Decoder\n",
        "    decoder_input = keras.Input(shape=input_shape)\n",
        "    dec = decoder_input\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        dec = transformer_decoder(dec, x, head_size, num_heads, ff_dim, dropout, l2_reg)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    dec = layers.Flatten()(dec)\n",
        "    x = layers.Concatenate()([x, dec])\n",
        "\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model([inputs, decoder_input], outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1d648db6",
      "metadata": {
        "id": "1d648db6"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters\n",
        "\"\"\"\n",
        "# THIS IS THE PART YOU SHOULD PLAY AROUND WITH\n",
        "# YOU MAY REDUCE THESE NUMBERS IF YOUR MACHINE IS OTHERWISE INCAPABLE OF RUNNING THE CODE\"\"\"\n",
        "\n",
        "head_size = 4\n",
        "num_heads = 4\n",
        "ff_dim = 256\n",
        "num_transformer_blocks = 4\n",
        "mlp_units = [256]\n",
        "dropout = 0.1\n",
        "mlp_dropout = 0.1\n",
        "initial_lr = 0.001\n",
        "l2_reg=0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6c794103",
      "metadata": {
        "id": "6c794103"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "64e4c3ef",
      "metadata": {
        "id": "64e4c3ef"
      },
      "outputs": [],
      "source": [
        "# Create the optimizer with the initial learning rate\n",
        "optimizer = Adam(learning_rate=initial_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0e19e795",
      "metadata": {
        "id": "0e19e795"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "02a51f0f",
      "metadata": {
        "id": "02a51f0f"
      },
      "outputs": [],
      "source": [
        "# Create the ReduceLROnPlateau callback\n",
        "lr_callback = ReduceLROnPlateau(factor=0.1, patience=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "511f6219",
      "metadata": {
        "id": "511f6219"
      },
      "outputs": [],
      "source": [
        "# Record the start time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "19d80153",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19d80153",
        "outputId": "79d966c3-6428-431a-f628-370fdb70a71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "908/908 [==============================] - 93s 62ms/step - loss: 1.9951 - accuracy: 0.6064 - val_loss: 0.6506 - val_accuracy: 0.7711 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.6343 - accuracy: 0.7992 - val_loss: 0.3893 - val_accuracy: 0.8807 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "908/908 [==============================] - 56s 61ms/step - loss: 0.4154 - accuracy: 0.8659 - val_loss: 0.2950 - val_accuracy: 0.9140 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "908/908 [==============================] - 57s 63ms/step - loss: 0.3182 - accuracy: 0.8961 - val_loss: 0.2789 - val_accuracy: 0.8967 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.2718 - accuracy: 0.9103 - val_loss: 0.2189 - val_accuracy: 0.9323 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.2356 - accuracy: 0.9230 - val_loss: 0.1896 - val_accuracy: 0.9343 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "908/908 [==============================] - 54s 59ms/step - loss: 0.2172 - accuracy: 0.9280 - val_loss: 0.1664 - val_accuracy: 0.9556 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "908/908 [==============================] - 52s 57ms/step - loss: 0.1932 - accuracy: 0.9361 - val_loss: 0.1467 - val_accuracy: 0.9508 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "908/908 [==============================] - 50s 55ms/step - loss: 0.1855 - accuracy: 0.9403 - val_loss: 0.1478 - val_accuracy: 0.9476 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "908/908 [==============================] - 52s 57ms/step - loss: 0.1768 - accuracy: 0.9425 - val_loss: 0.1503 - val_accuracy: 0.9593 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.1664 - accuracy: 0.9465 - val_loss: 0.1319 - val_accuracy: 0.9618 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "908/908 [==============================] - 53s 59ms/step - loss: 0.1578 - accuracy: 0.9501 - val_loss: 0.1382 - val_accuracy: 0.9482 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.1520 - accuracy: 0.9501 - val_loss: 0.1095 - val_accuracy: 0.9670 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "908/908 [==============================] - 56s 61ms/step - loss: 0.1494 - accuracy: 0.9526 - val_loss: 0.1056 - val_accuracy: 0.9677 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.1477 - accuracy: 0.9539 - val_loss: 0.1309 - val_accuracy: 0.9523 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.1340 - accuracy: 0.9568 - val_loss: 0.1353 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.1305 - accuracy: 0.9579 - val_loss: 0.0926 - val_accuracy: 0.9719 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.1390 - accuracy: 0.9553 - val_loss: 0.0855 - val_accuracy: 0.9706 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.1192 - accuracy: 0.9622 - val_loss: 0.0958 - val_accuracy: 0.9695 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "908/908 [==============================] - 56s 61ms/step - loss: 0.1229 - accuracy: 0.9620 - val_loss: 0.1120 - val_accuracy: 0.9613 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "908/908 [==============================] - 54s 60ms/step - loss: 0.1292 - accuracy: 0.9594 - val_loss: 0.1217 - val_accuracy: 0.9651 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "908/908 [==============================] - 54s 60ms/step - loss: 0.1180 - accuracy: 0.9635 - val_loss: 0.0885 - val_accuracy: 0.9706 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "908/908 [==============================] - 54s 59ms/step - loss: 0.1135 - accuracy: 0.9638 - val_loss: 0.1297 - val_accuracy: 0.9720 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.1158 - accuracy: 0.9642 - val_loss: 0.1050 - val_accuracy: 0.9655 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.1283 - accuracy: 0.9607 - val_loss: 0.0756 - val_accuracy: 0.9785 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.1035 - accuracy: 0.9679 - val_loss: 0.1002 - val_accuracy: 0.9761 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "908/908 [==============================] - 54s 59ms/step - loss: 0.1106 - accuracy: 0.9657 - val_loss: 0.0828 - val_accuracy: 0.9774 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.1173 - accuracy: 0.9639 - val_loss: 0.1033 - val_accuracy: 0.9695 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.1055 - accuracy: 0.9672 - val_loss: 0.1029 - val_accuracy: 0.9607 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.1045 - accuracy: 0.9669 - val_loss: 0.0872 - val_accuracy: 0.9753 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "908/908 [==============================] - 53s 59ms/step - loss: 0.1008 - accuracy: 0.9679 - val_loss: 0.0810 - val_accuracy: 0.9762 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.1022 - accuracy: 0.9691 - val_loss: 0.0608 - val_accuracy: 0.9800 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.1104 - accuracy: 0.9676 - val_loss: 0.3046 - val_accuracy: 0.9324 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.1064 - accuracy: 0.9675 - val_loss: 0.0883 - val_accuracy: 0.9718 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.1033 - accuracy: 0.9687 - val_loss: 0.0589 - val_accuracy: 0.9885 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "908/908 [==============================] - 57s 63ms/step - loss: 0.1002 - accuracy: 0.9686 - val_loss: 0.0724 - val_accuracy: 0.9818 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "908/908 [==============================] - 57s 62ms/step - loss: 0.0950 - accuracy: 0.9719 - val_loss: 0.0735 - val_accuracy: 0.9802 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0974 - accuracy: 0.9701 - val_loss: 0.0764 - val_accuracy: 0.9809 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "908/908 [==============================] - 58s 64ms/step - loss: 0.0963 - accuracy: 0.9705 - val_loss: 0.0482 - val_accuracy: 0.9892 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "908/908 [==============================] - 57s 63ms/step - loss: 0.0997 - accuracy: 0.9702 - val_loss: 0.0594 - val_accuracy: 0.9817 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0942 - accuracy: 0.9721 - val_loss: 0.1033 - val_accuracy: 0.9670 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "908/908 [==============================] - 57s 63ms/step - loss: 0.0975 - accuracy: 0.9702 - val_loss: 0.0601 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "908/908 [==============================] - 57s 63ms/step - loss: 0.0888 - accuracy: 0.9725 - val_loss: 0.0721 - val_accuracy: 0.9777 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0986 - accuracy: 0.9705 - val_loss: 0.1198 - val_accuracy: 0.9665 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.1015 - accuracy: 0.9700 - val_loss: 0.0831 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.0956 - accuracy: 0.9706 - val_loss: 0.0605 - val_accuracy: 0.9867 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.0939 - accuracy: 0.9720 - val_loss: 0.0743 - val_accuracy: 0.9787 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "908/908 [==============================] - 52s 57ms/step - loss: 0.0952 - accuracy: 0.9731 - val_loss: 0.0773 - val_accuracy: 0.9797 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "908/908 [==============================] - 52s 57ms/step - loss: 0.1097 - accuracy: 0.9684 - val_loss: 0.0723 - val_accuracy: 0.9786 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "908/908 [==============================] - 51s 56ms/step - loss: 0.0973 - accuracy: 0.9714 - val_loss: 0.0767 - val_accuracy: 0.9760 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "908/908 [==============================] - 50s 55ms/step - loss: 0.0878 - accuracy: 0.9741 - val_loss: 0.0645 - val_accuracy: 0.9815 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.0990 - accuracy: 0.9708 - val_loss: 0.0673 - val_accuracy: 0.9828 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "908/908 [==============================] - 51s 56ms/step - loss: 0.0933 - accuracy: 0.9722 - val_loss: 0.0677 - val_accuracy: 0.9793 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0898 - accuracy: 0.9724 - val_loss: 0.0508 - val_accuracy: 0.9886 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0873 - accuracy: 0.9742 - val_loss: 0.0560 - val_accuracy: 0.9893 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0905 - accuracy: 0.9732 - val_loss: 0.0559 - val_accuracy: 0.9857 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "908/908 [==============================] - 54s 59ms/step - loss: 0.0870 - accuracy: 0.9754 - val_loss: 0.0599 - val_accuracy: 0.9824 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.0932 - accuracy: 0.9726 - val_loss: 0.0929 - val_accuracy: 0.9733 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0828 - accuracy: 0.9761 - val_loss: 0.1099 - val_accuracy: 0.9769 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0953 - accuracy: 0.9715 - val_loss: 0.0609 - val_accuracy: 0.9762 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "908/908 [==============================] - 54s 59ms/step - loss: 0.0892 - accuracy: 0.9740 - val_loss: 0.0566 - val_accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "908/908 [==============================] - 54s 59ms/step - loss: 0.0838 - accuracy: 0.9750 - val_loss: 0.0482 - val_accuracy: 0.9867 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0878 - accuracy: 0.9745 - val_loss: 0.1032 - val_accuracy: 0.9674 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0957 - accuracy: 0.9715 - val_loss: 0.1465 - val_accuracy: 0.9566 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.1111 - accuracy: 0.9716 - val_loss: 0.0466 - val_accuracy: 0.9898 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0829 - accuracy: 0.9752 - val_loss: 0.0764 - val_accuracy: 0.9753 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 0.0524 - val_accuracy: 0.9886 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "908/908 [==============================] - 54s 59ms/step - loss: 0.0898 - accuracy: 0.9740 - val_loss: 0.0605 - val_accuracy: 0.9821 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "908/908 [==============================] - 53s 59ms/step - loss: 0.0847 - accuracy: 0.9755 - val_loss: 0.0886 - val_accuracy: 0.9717 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0837 - accuracy: 0.9751 - val_loss: 0.0577 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "908/908 [==============================] - 53s 59ms/step - loss: 0.0833 - accuracy: 0.9756 - val_loss: 0.0577 - val_accuracy: 0.9874 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "908/908 [==============================] - 56s 61ms/step - loss: 0.0797 - accuracy: 0.9759 - val_loss: 0.0730 - val_accuracy: 0.9809 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "908/908 [==============================] - 56s 61ms/step - loss: 0.0861 - accuracy: 0.9753 - val_loss: 0.0479 - val_accuracy: 0.9863 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.0886 - accuracy: 0.9733 - val_loss: 0.0436 - val_accuracy: 0.9911 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "908/908 [==============================] - 57s 62ms/step - loss: 0.0822 - accuracy: 0.9763 - val_loss: 0.0492 - val_accuracy: 0.9887 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0857 - accuracy: 0.9753 - val_loss: 0.0751 - val_accuracy: 0.9759 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.0852 - accuracy: 0.9763 - val_loss: 0.0515 - val_accuracy: 0.9879 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "908/908 [==============================] - 54s 60ms/step - loss: 0.0781 - accuracy: 0.9774 - val_loss: 0.0454 - val_accuracy: 0.9885 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "908/908 [==============================] - 53s 59ms/step - loss: 0.0867 - accuracy: 0.9753 - val_loss: 0.0464 - val_accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.0790 - accuracy: 0.9764 - val_loss: 0.0639 - val_accuracy: 0.9816 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.0870 - accuracy: 0.9746 - val_loss: 0.0466 - val_accuracy: 0.9895 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "908/908 [==============================] - 52s 58ms/step - loss: 0.0778 - accuracy: 0.9777 - val_loss: 0.0818 - val_accuracy: 0.9711 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "908/908 [==============================] - 50s 55ms/step - loss: 0.0873 - accuracy: 0.9752 - val_loss: 0.1087 - val_accuracy: 0.9799 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "908/908 [==============================] - 53s 58ms/step - loss: 0.0837 - accuracy: 0.9756 - val_loss: 0.0555 - val_accuracy: 0.9825 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "908/908 [==============================] - 52s 58ms/step - loss: 0.0833 - accuracy: 0.9752 - val_loss: 0.0569 - val_accuracy: 0.9819 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.0817 - accuracy: 0.9770 - val_loss: 0.0727 - val_accuracy: 0.9824 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "908/908 [==============================] - 54s 59ms/step - loss: 0.0853 - accuracy: 0.9756 - val_loss: 0.0397 - val_accuracy: 0.9899 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "908/908 [==============================] - 57s 63ms/step - loss: 0.0731 - accuracy: 0.9781 - val_loss: 0.0459 - val_accuracy: 0.9845 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.0862 - accuracy: 0.9755 - val_loss: 0.0572 - val_accuracy: 0.9842 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "908/908 [==============================] - 56s 61ms/step - loss: 0.0772 - accuracy: 0.9788 - val_loss: 0.0392 - val_accuracy: 0.9904 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0794 - accuracy: 0.9771 - val_loss: 0.0727 - val_accuracy: 0.9815 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0802 - accuracy: 0.9768 - val_loss: 0.0526 - val_accuracy: 0.9855 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0752 - accuracy: 0.9779 - val_loss: 0.0646 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "908/908 [==============================] - 57s 63ms/step - loss: 0.0811 - accuracy: 0.9772 - val_loss: 0.0542 - val_accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.0748 - accuracy: 0.9783 - val_loss: 0.0515 - val_accuracy: 0.9849 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "908/908 [==============================] - 57s 62ms/step - loss: 0.0755 - accuracy: 0.9788 - val_loss: 0.0632 - val_accuracy: 0.9799 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0822 - accuracy: 0.9767 - val_loss: 0.0672 - val_accuracy: 0.9792 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "908/908 [==============================] - 55s 60ms/step - loss: 0.0765 - accuracy: 0.9793 - val_loss: 0.0597 - val_accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "908/908 [==============================] - 56s 62ms/step - loss: 0.0750 - accuracy: 0.9789 - val_loss: 0.0475 - val_accuracy: 0.9899 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "908/908 [==============================] - 55s 61ms/step - loss: 0.0802 - accuracy: 0.9775 - val_loss: 0.1537 - val_accuracy: 0.9809 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x797cb3162aa0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.fit([x_train, x_train], y_train,\n",
        "          batch_size=64,\n",
        "          epochs=100,\n",
        "          validation_data=([x_val, x_val], y_val),\n",
        "          callbacks=[lr_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3ffe7d0c",
      "metadata": {
        "id": "3ffe7d0c"
      },
      "outputs": [],
      "source": [
        "# Record the end time\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e8dd9c65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8dd9c65",
        "outputId": "daac2f76-9987-47b7-f41d-251b28607698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Running Time: 5503.74 seconds\n"
          ]
        }
      ],
      "source": [
        "# Calculate the total running time\n",
        "running_time = end_time - start_time\n",
        "print(\"Total Running Time: {:.2f} seconds\".format(running_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "23ebca14",
      "metadata": {
        "id": "23ebca14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74033ac9-e80a-4674-cf47-323eeef9f302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252/252 [==============================] - 5s 20ms/step - loss: 0.1321 - accuracy: 0.9800\n",
            "Test loss: 0.13210539519786835, Test accuracy: 0.9800322651863098\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([x_test, x_test], y_test)\n",
        "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "78f8e19d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78f8e19d",
        "outputId": "9405d5f8-7e30-435b-ea12-a2f30250422a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "model.save(\"my_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}