{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassanaljaber/Data-IoT/blob/main/Model_Engineering_442_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "da645ec0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "da645ec0",
        "outputId": "a83fcad1-bdcb-49df-9d83-7dd243318d83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nYOUR TASKS:\\n\\n1. SPECIFY THE URL OR PATH TO YOUR DATA, REMEMBER - YOU FIRST HAVE TO DOWNLOAD IT.\\n2. CLICK RUN ALL OR RESTART AND RUN ALL BUTTON TO RUN THE CODE. THIS CODE RUNS IN A CHRONOLOGICAL MANNER - THE TOP BLOCKS MUST PRECEED THE BOTTOM ONES, \\n                                                                                                            i.e. don't run stuff from the bottom first, otherwise the code won't work properly.\\n3. NEAR THE END OF THE CODE, YOU WILL SEE YOUR EPOCH METRICS, AS I STATED IN CLASS, YOU WANT THE ACCURACY TO APPROACH 100% =1.0 AND THE LOSS TO APPROACH 0\\n4. IN CASE IF YOUR MODEL IS STRUGGLING TO REACH THESE RESULTS AND IS INSTEAD STUCK AT A LOW ACCURACY, NAVIGATE TO THE BLOCK OF CODE WITH HYPERPARAMETERS AND CHANGE THESE NUMBERS,\\nTHEN, TRY RUNNING THE CODE AGAIN AND SEE HOW YOUR MODEL IS PERFORMING; REPEAT UNTIL YOU REACH A PLAUSIBLE RESULT (ONE THAT IS BETTER THAN A COIN TOSS IN TERMS OF PREDICTION ACCURACY IN THE WORST CASE)\\n5. SAVE YOUR RESULTS => THE CODE INCLUDES A BLOCK WHICH WILL SAVE YOUR MODEL TO A .h5 FILE,\\n - KEEP THE OUTPUTS OF THIS NOTEBOOK AS WELL, YOU WILL WANT TO DEMONSTRATE HOW THE TRAINING PROCESS WENT.\\n - BE MINDFUL OF THE TIME YOU HAVE IF YOU CHOOSE TO USE GOOGLE COLLABORATORY INSTEAD OF YOUR OWN MACHINE AS THEIR VMs ONLY OFFER YOU A COUPLE OF HOURS OF USAGE.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "YOUR TASKS:\n",
        "\n",
        "1. SPECIFY THE URL OR PATH TO YOUR DATA, REMEMBER - YOU FIRST HAVE TO DOWNLOAD IT.\n",
        "2. CLICK RUN ALL OR RESTART AND RUN ALL BUTTON TO RUN THE CODE. THIS CODE RUNS IN A CHRONOLOGICAL MANNER - THE TOP BLOCKS MUST PRECEED THE BOTTOM ONES,\n",
        "                                                                                                            i.e. don't run stuff from the bottom first, otherwise the code won't work properly.\n",
        "3. NEAR THE END OF THE CODE, YOU WILL SEE YOUR EPOCH METRICS, AS I STATED IN CLASS, YOU WANT THE ACCURACY TO APPROACH 100% =1.0 AND THE LOSS TO APPROACH 0\n",
        "4. IN CASE IF YOUR MODEL IS STRUGGLING TO REACH THESE RESULTS AND IS INSTEAD STUCK AT A LOW ACCURACY, NAVIGATE TO THE BLOCK OF CODE WITH HYPERPARAMETERS AND CHANGE THESE NUMBERS,\n",
        "THEN, TRY RUNNING THE CODE AGAIN AND SEE HOW YOUR MODEL IS PERFORMING; REPEAT UNTIL YOU REACH A PLAUSIBLE RESULT (ONE THAT IS BETTER THAN A COIN TOSS IN TERMS OF PREDICTION ACCURACY IN THE WORST CASE)\n",
        "5. SAVE YOUR RESULTS => THE CODE INCLUDES A BLOCK WHICH WILL SAVE YOUR MODEL TO A .h5 FILE,\n",
        " - KEEP THE OUTPUTS OF THIS NOTEBOOK AS WELL, YOU WILL WANT TO DEMONSTRATE HOW THE TRAINING PROCESS WENT.\n",
        " - BE MINDFUL OF THE TIME YOU HAVE IF YOU CHOOSE TO USE GOOGLE COLLABORATORY INSTEAD OF YOUR OWN MACHINE AS THEIR VMs ONLY OFFER YOU A COUPLE OF HOURS OF USAGE.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd77aa5b",
      "metadata": {
        "id": "dd77aa5b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f16df2f1",
      "metadata": {
        "id": "f16df2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99aad52c-9020-44c4-d642-cf5add1adb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e16cb29338de>:10: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  data.iloc[:, -1] = label_encoder.fit_transform(data.iloc[:, -1])\n"
          ]
        }
      ],
      "source": [
        "# Function to read the data\n",
        "def read_data(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "\n",
        "    # Extract features\n",
        "    features = data.iloc[:,1 :-1].values\n",
        "\n",
        "    # Extract and encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    data.iloc[:, -1] = label_encoder.fit_transform(data.iloc[:, -1])\n",
        "    labels = data.iloc[:, -1].values\n",
        "\n",
        "    return features, labels\n",
        "# Read the data\n",
        "data_url = \"https://raw.githubusercontent.com/hassanaljaber/Data-IoT/main/data%20IoT.csv\" # enter your data URL or PATH here in enclosed in \" \" IF YOUR NOTEBOOK IS IN THE SAME FOLDER AS data.csv, which is your data you downloaded, then this will run as it is.\n",
        "                    # otherwise, you have to specify a different path or url\n",
        "x, y = read_data(data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3eb86201",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eb86201",
        "outputId": "6f617cc8-8810-40b8-8bf1-a3b9c554653c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80590, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x.shape ### IN THE FOLLOWING PARTS OF THE CODE, MAKE SURE THAT EVERYTING IS LOADED CORRECTLY, YOU SHOULD HAVE A DATASET WITH 22 CLASSES, (n-rows, 6 columns, later another dimension will be added here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6b640bf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b640bf8",
        "outputId": "7eb7a757-67e3-43e0-ff71-14746e423011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80590,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9650592c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9650592c",
        "outputId": "cd0b381a-ad55-4d96-960b-68d17a2518eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "np.unique(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0edc69b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0edc69b6",
        "outputId": "818214fa-73d9-4ec5-bd07-1d57b02893b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 60.70153 ,   3.478926, -12.537908,   0.82506 ,   0.8963  ,\n",
              "        -0.344533])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b4eec323",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4eec323",
        "outputId": "1bc4d84c-e4cc-4108-a7b2-1e2b2496463d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y[0] # these were sample rows from the data for your to inspect, you should see a 6 by 1 vector above and a single value here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9db6440b",
      "metadata": {
        "id": "9db6440b"
      },
      "outputs": [],
      "source": [
        "# Split the data into training, validation, and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0b135163",
      "metadata": {
        "id": "0b135163"
      },
      "outputs": [],
      "source": [
        "# Reshape the data\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "936243fe",
      "metadata": {
        "id": "936243fe"
      },
      "outputs": [],
      "source": [
        "# Determine the input shape and number of classes\n",
        "input_shape = (x_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4cb2989e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cb2989e",
        "outputId": "5dbc1b3a-882c-45d0-fc25-9e11bde1300a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "num_classes # must have 22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "26c6890e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26c6890e",
        "outputId": "a3d9d36a-5380-4f90-8037-4a62e5298fa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "859aa647",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "859aa647",
        "outputId": "005c918b-7666-4611-b8d4-20de73c27588"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58024, 6, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "eab565dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eab565dd",
        "outputId": "d6323859-f31e-410f-b582-0a7c08f1e9dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58024,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ab950213",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab950213",
        "outputId": "154b931f-004b-40ca-d4fd-7d0e5ba74959"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.05572590e+01],\n",
              "       [-2.39156280e+01],\n",
              "       [-1.79886032e+02],\n",
              "       [ 1.07236000e+00],\n",
              "       [ 1.38438800e+00],\n",
              "       [ 1.14208000e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7f11432f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f11432f",
        "outputId": "e4cbb993-9141-4c5f-9643-cbdc2a8a23de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cd51204b",
      "metadata": {
        "id": "cd51204b"
      },
      "outputs": [],
      "source": [
        "# Transformer Encoder function with dropout and L2 regularization\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.1, l2_reg=0.01):\n",
        "\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed-forward network with dropout and L2 regularization\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(inputs.shape[-1], activation = 'softmax')(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return x + res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9df843aa",
      "metadata": {
        "id": "9df843aa"
      },
      "outputs": [],
      "source": [
        "# Transformer Decoder function\n",
        "def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0.1, l2_reg=0.01):\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(res, enc_outputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = x + res\n",
        "\n",
        "    # Feed-forward network\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    '''\n",
        "    YOU MAY WANT TO ADD OR REMOVE THESE TWO LINES HERE PRECISELY IN THIS PART OF THE CODE, PAY ATTENTION TO THE INDENTATION, PYTHON REQUIRES CONSISTENCY IN ORDER FOR THE CODE TO RUN CORRECTLY\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    '''\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(inputs.shape[-1], activation = 'softmax')(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return x + res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d9851305",
      "metadata": {
        "id": "d9851305"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0, l2_reg=0):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Encoder\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout, l2_reg)\n",
        "\n",
        "\n",
        "    # Decoder\n",
        "    decoder_input = keras.Input(shape=input_shape)\n",
        "    dec = decoder_input\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        dec = transformer_decoder(dec, x, head_size, num_heads, ff_dim, dropout, l2_reg)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    dec = layers.Flatten()(dec)\n",
        "    x = layers.Concatenate()([x, dec])\n",
        "\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model([inputs, decoder_input], outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1d648db6",
      "metadata": {
        "id": "1d648db6"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters\n",
        "\"\"\"\n",
        "# THIS IS THE PART YOU SHOULD PLAY AROUND WITH\n",
        "# YOU MAY REDUCE THESE NUMBERS IF YOUR MACHINE IS OTHERWISE INCAPABLE OF RUNNING THE CODE\"\"\"\n",
        "\n",
        "head_size = 4\n",
        "num_heads = 4\n",
        "ff_dim = 256\n",
        "num_transformer_blocks = 4\n",
        "mlp_units = [256]\n",
        "dropout = 0.1\n",
        "mlp_dropout = 0.1\n",
        "initial_lr = 0.001\n",
        "l2_reg=0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6c794103",
      "metadata": {
        "id": "6c794103"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "64e4c3ef",
      "metadata": {
        "id": "64e4c3ef"
      },
      "outputs": [],
      "source": [
        "# Create the optimizer with the initial learning rate\n",
        "optimizer = Adam(learning_rate=initial_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0e19e795",
      "metadata": {
        "id": "0e19e795"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "02a51f0f",
      "metadata": {
        "id": "02a51f0f"
      },
      "outputs": [],
      "source": [
        "# Create the ReduceLROnPlateau callback\n",
        "lr_callback = ReduceLROnPlateau(factor=0.1, patience=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "511f6219",
      "metadata": {
        "id": "511f6219"
      },
      "outputs": [],
      "source": [
        "# Record the start time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "19d80153",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19d80153",
        "outputId": "ae92d7ec-27bf-4a55-e017-b798cff6b5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "907/907 [==============================] - 86s 56ms/step - loss: 2.7902 - accuracy: 0.3959 - val_loss: 1.1705 - val_accuracy: 0.5838 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 1.1748 - accuracy: 0.5805 - val_loss: 0.9019 - val_accuracy: 0.6904 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.9288 - accuracy: 0.6653 - val_loss: 0.7565 - val_accuracy: 0.7496 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.7585 - accuracy: 0.7245 - val_loss: 0.6359 - val_accuracy: 0.7838 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.6264 - accuracy: 0.7675 - val_loss: 0.4893 - val_accuracy: 0.8337 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.5372 - accuracy: 0.7967 - val_loss: 0.4751 - val_accuracy: 0.8262 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.4918 - accuracy: 0.8134 - val_loss: 0.4418 - val_accuracy: 0.8228 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "907/907 [==============================] - 50s 56ms/step - loss: 0.4504 - accuracy: 0.8267 - val_loss: 0.3702 - val_accuracy: 0.8647 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.4260 - accuracy: 0.8337 - val_loss: 0.3307 - val_accuracy: 0.8745 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "907/907 [==============================] - 50s 56ms/step - loss: 0.4058 - accuracy: 0.8428 - val_loss: 0.3356 - val_accuracy: 0.8808 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "907/907 [==============================] - 50s 56ms/step - loss: 0.3731 - accuracy: 0.8555 - val_loss: 0.3379 - val_accuracy: 0.8685 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "907/907 [==============================] - 48s 53ms/step - loss: 0.3613 - accuracy: 0.8591 - val_loss: 0.2975 - val_accuracy: 0.8809 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.3474 - accuracy: 0.8640 - val_loss: 0.3236 - val_accuracy: 0.8770 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "907/907 [==============================] - 48s 53ms/step - loss: 0.3314 - accuracy: 0.8706 - val_loss: 0.2782 - val_accuracy: 0.9024 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.3247 - accuracy: 0.8746 - val_loss: 0.2631 - val_accuracy: 0.8972 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.3122 - accuracy: 0.8794 - val_loss: 0.2647 - val_accuracy: 0.8921 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.3051 - accuracy: 0.8822 - val_loss: 0.3007 - val_accuracy: 0.8874 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2973 - accuracy: 0.8859 - val_loss: 0.2650 - val_accuracy: 0.8938 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "907/907 [==============================] - 50s 56ms/step - loss: 0.2923 - accuracy: 0.8902 - val_loss: 0.3086 - val_accuracy: 0.8712 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2934 - accuracy: 0.8888 - val_loss: 0.2322 - val_accuracy: 0.9134 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "907/907 [==============================] - 50s 56ms/step - loss: 0.2908 - accuracy: 0.8911 - val_loss: 0.2093 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2857 - accuracy: 0.8915 - val_loss: 0.2409 - val_accuracy: 0.9083 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "907/907 [==============================] - 50s 56ms/step - loss: 0.2746 - accuracy: 0.8948 - val_loss: 0.2315 - val_accuracy: 0.9015 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2722 - accuracy: 0.8979 - val_loss: 0.1937 - val_accuracy: 0.9320 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2662 - accuracy: 0.8985 - val_loss: 0.2235 - val_accuracy: 0.9201 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2718 - accuracy: 0.8955 - val_loss: 0.1899 - val_accuracy: 0.9316 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "907/907 [==============================] - 48s 53ms/step - loss: 0.2665 - accuracy: 0.8990 - val_loss: 0.2099 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.2470 - accuracy: 0.9053 - val_loss: 0.2134 - val_accuracy: 0.9168 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2679 - accuracy: 0.8991 - val_loss: 0.2054 - val_accuracy: 0.9196 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2450 - accuracy: 0.9068 - val_loss: 0.2602 - val_accuracy: 0.8956 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2586 - accuracy: 0.9026 - val_loss: 0.1747 - val_accuracy: 0.9360 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2533 - accuracy: 0.9035 - val_loss: 0.1882 - val_accuracy: 0.9296 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2424 - accuracy: 0.9078 - val_loss: 0.1840 - val_accuracy: 0.9329 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.2438 - accuracy: 0.9085 - val_loss: 0.2410 - val_accuracy: 0.9120 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2469 - accuracy: 0.9079 - val_loss: 0.2334 - val_accuracy: 0.9155 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2400 - accuracy: 0.9092 - val_loss: 0.2317 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2400 - accuracy: 0.9096 - val_loss: 0.2160 - val_accuracy: 0.9178 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.2402 - accuracy: 0.9108 - val_loss: 0.1738 - val_accuracy: 0.9353 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2393 - accuracy: 0.9084 - val_loss: 0.2134 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2362 - accuracy: 0.9110 - val_loss: 0.1819 - val_accuracy: 0.9289 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2324 - accuracy: 0.9120 - val_loss: 0.1886 - val_accuracy: 0.9260 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.2343 - accuracy: 0.9116 - val_loss: 0.1934 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2260 - accuracy: 0.9137 - val_loss: 0.1761 - val_accuracy: 0.9398 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.2279 - accuracy: 0.9138 - val_loss: 0.2261 - val_accuracy: 0.9041 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "907/907 [==============================] - 48s 53ms/step - loss: 0.2281 - accuracy: 0.9144 - val_loss: 0.1953 - val_accuracy: 0.9242 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2297 - accuracy: 0.9137 - val_loss: 0.1790 - val_accuracy: 0.9341 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.2166 - accuracy: 0.9190 - val_loss: 0.1690 - val_accuracy: 0.9383 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.2188 - accuracy: 0.9175 - val_loss: 0.1750 - val_accuracy: 0.9284 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2293 - accuracy: 0.9139 - val_loss: 0.1916 - val_accuracy: 0.9251 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2246 - accuracy: 0.9170 - val_loss: 0.1734 - val_accuracy: 0.9389 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.2208 - accuracy: 0.9172 - val_loss: 0.1744 - val_accuracy: 0.9352 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2147 - accuracy: 0.9192 - val_loss: 0.1564 - val_accuracy: 0.9389 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2211 - accuracy: 0.9174 - val_loss: 0.1819 - val_accuracy: 0.9221 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.2133 - accuracy: 0.9209 - val_loss: 0.2399 - val_accuracy: 0.9085 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2195 - accuracy: 0.9192 - val_loss: 0.1640 - val_accuracy: 0.9406 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2178 - accuracy: 0.9174 - val_loss: 0.1636 - val_accuracy: 0.9307 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.2153 - accuracy: 0.9206 - val_loss: 0.1637 - val_accuracy: 0.9390 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2103 - accuracy: 0.9210 - val_loss: 0.2024 - val_accuracy: 0.9262 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.2173 - accuracy: 0.9211 - val_loss: 0.1695 - val_accuracy: 0.9364 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2081 - accuracy: 0.9230 - val_loss: 0.1714 - val_accuracy: 0.9342 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "907/907 [==============================] - 55s 61ms/step - loss: 0.2230 - accuracy: 0.9184 - val_loss: 0.1912 - val_accuracy: 0.9293 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2157 - accuracy: 0.9191 - val_loss: 0.1896 - val_accuracy: 0.9255 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2105 - accuracy: 0.9203 - val_loss: 0.1668 - val_accuracy: 0.9400 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.2093 - accuracy: 0.9215 - val_loss: 0.2276 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2103 - accuracy: 0.9216 - val_loss: 0.1672 - val_accuracy: 0.9325 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2132 - accuracy: 0.9209 - val_loss: 0.1626 - val_accuracy: 0.9365 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2031 - accuracy: 0.9243 - val_loss: 0.1875 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2074 - accuracy: 0.9213 - val_loss: 0.1705 - val_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.2105 - accuracy: 0.9222 - val_loss: 0.1499 - val_accuracy: 0.9437 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2010 - accuracy: 0.9246 - val_loss: 0.1574 - val_accuracy: 0.9373 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2045 - accuracy: 0.9246 - val_loss: 0.1601 - val_accuracy: 0.9422 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2034 - accuracy: 0.9242 - val_loss: 0.1513 - val_accuracy: 0.9471 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2079 - accuracy: 0.9213 - val_loss: 0.1614 - val_accuracy: 0.9352 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2088 - accuracy: 0.9225 - val_loss: 0.1562 - val_accuracy: 0.9432 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2050 - accuracy: 0.9243 - val_loss: 0.1582 - val_accuracy: 0.9369 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2050 - accuracy: 0.9258 - val_loss: 0.1908 - val_accuracy: 0.9253 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.2096 - accuracy: 0.9247 - val_loss: 0.1690 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.2053 - accuracy: 0.9240 - val_loss: 0.1534 - val_accuracy: 0.9424 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2003 - accuracy: 0.9257 - val_loss: 0.1793 - val_accuracy: 0.9239 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "907/907 [==============================] - 56s 62ms/step - loss: 0.2002 - accuracy: 0.9264 - val_loss: 0.1526 - val_accuracy: 0.9444 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "907/907 [==============================] - 60s 66ms/step - loss: 0.1997 - accuracy: 0.9266 - val_loss: 0.1646 - val_accuracy: 0.9362 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2032 - accuracy: 0.9244 - val_loss: 0.1555 - val_accuracy: 0.9411 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.1918 - accuracy: 0.9275 - val_loss: 0.1679 - val_accuracy: 0.9322 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.1992 - accuracy: 0.9259 - val_loss: 0.2411 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2030 - accuracy: 0.9252 - val_loss: 0.1550 - val_accuracy: 0.9362 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.1921 - accuracy: 0.9292 - val_loss: 0.1948 - val_accuracy: 0.9315 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.1899 - accuracy: 0.9287 - val_loss: 0.1525 - val_accuracy: 0.9440 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2005 - accuracy: 0.9256 - val_loss: 0.1861 - val_accuracy: 0.9344 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2040 - accuracy: 0.9262 - val_loss: 0.1496 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2004 - accuracy: 0.9266 - val_loss: 0.1560 - val_accuracy: 0.9456 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.1926 - accuracy: 0.9282 - val_loss: 0.1479 - val_accuracy: 0.9431 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2011 - accuracy: 0.9270 - val_loss: 0.1529 - val_accuracy: 0.9403 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.1998 - accuracy: 0.9272 - val_loss: 0.1484 - val_accuracy: 0.9460 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.1892 - accuracy: 0.9291 - val_loss: 0.1754 - val_accuracy: 0.9395 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "907/907 [==============================] - 56s 62ms/step - loss: 0.1963 - accuracy: 0.9272 - val_loss: 0.1441 - val_accuracy: 0.9481 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.1994 - accuracy: 0.9267 - val_loss: 0.1661 - val_accuracy: 0.9358 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "907/907 [==============================] - 49s 54ms/step - loss: 0.1948 - accuracy: 0.9282 - val_loss: 0.1486 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.1908 - accuracy: 0.9290 - val_loss: 0.1657 - val_accuracy: 0.9452 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "907/907 [==============================] - 49s 55ms/step - loss: 0.1965 - accuracy: 0.9286 - val_loss: 0.1537 - val_accuracy: 0.9402 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.1969 - accuracy: 0.9271 - val_loss: 0.1475 - val_accuracy: 0.9461 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7da500234fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model.fit([x_train, x_train], y_train,\n",
        "          batch_size=64,\n",
        "          epochs=100,\n",
        "          validation_data=([x_val, x_val], y_val),\n",
        "          callbacks=[lr_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3ffe7d0c",
      "metadata": {
        "id": "3ffe7d0c"
      },
      "outputs": [],
      "source": [
        "# Record the end time\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e8dd9c65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8dd9c65",
        "outputId": "867d7824-249a-4672-9144-90ba4860ef3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Running Time: 5606.16 seconds\n"
          ]
        }
      ],
      "source": [
        "# Calculate the total running time\n",
        "running_time = end_time - start_time\n",
        "print(\"Total Running Time: {:.2f} seconds\".format(running_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "23ebca14",
      "metadata": {
        "id": "23ebca14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26a6db1-d689-4879-f331-0ec4110c8530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252/252 [==============================] - 4s 15ms/step - loss: 0.1478 - accuracy: 0.9463\n",
            "Test loss: 0.14782170951366425, Test accuracy: 0.9462712407112122\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([x_test, x_test], y_test)\n",
        "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "78f8e19d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78f8e19d",
        "outputId": "b898aa14-7cd9-41f6-9c04-1bbf2d52ee4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "model.save(\"my_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}