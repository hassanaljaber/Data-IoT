{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassanaljaber/Data-IoT/blob/main/Model_Engineering_442_(2)_yousuf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da645ec0",
      "metadata": {
        "id": "da645ec0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "YOUR TASKS:\n",
        "\n",
        "1. SPECIFY THE URL OR PATH TO YOUR DATA, REMEMBER - YOU FIRST HAVE TO DOWNLOAD IT.\n",
        "2. CLICK RUN ALL OR RESTART AND RUN ALL BUTTON TO RUN THE CODE. THIS CODE RUNS IN A CHRONOLOGICAL MANNER - THE TOP BLOCKS MUST PRECEED THE BOTTOM ONES,\n",
        "                                                                                                            i.e. don't run stuff from the bottom first, otherwise the code won't work properly.\n",
        "3. NEAR THE END OF THE CODE, YOU WILL SEE YOUR EPOCH METRICS, AS I STATED IN CLASS, YOU WANT THE ACCURACY TO APPROACH 100% =1.0 AND THE LOSS TO APPROACH 0\n",
        "4. IN CASE IF YOUR MODEL IS STRUGGLING TO REACH THESE RESULTS AND IS INSTEAD STUCK AT A LOW ACCURACY, NAVIGATE TO THE BLOCK OF CODE WITH HYPERPARAMETERS AND CHANGE THESE NUMBERS,\n",
        "THEN, TRY RUNNING THE CODE AGAIN AND SEE HOW YOUR MODEL IS PERFORMING; REPEAT UNTIL YOU REACH A PLAUSIBLE RESULT (ONE THAT IS BETTER THAN A COIN TOSS IN TERMS OF PREDICTION ACCURACY IN THE WORST CASE)\n",
        "5. SAVE YOUR RESULTS => THE CODE INCLUDES A BLOCK WHICH WILL SAVE YOUR MODEL TO A .h5 FILE,\n",
        " - KEEP THE OUTPUTS OF THIS NOTEBOOK AS WELL, YOU WILL WANT TO DEMONSTRATE HOW THE TRAINING PROCESS WENT.\n",
        " - BE MINDFUL OF THE TIME YOU HAVE IF YOU CHOOSE TO USE GOOGLE COLLABORATORY INSTEAD OF YOUR OWN MACHINE AS THEIR VMs ONLY OFFER YOU A COUPLE OF HOURS OF USAGE.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "dd77aa5b",
      "metadata": {
        "id": "dd77aa5b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f16df2f1",
      "metadata": {
        "id": "f16df2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9925181-9b5c-4464-e9db-1f130a4803c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-ad1614f497b8>:10: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  data.iloc[:, -1] = label_encoder.fit_transform(data.iloc[:, -1])\n"
          ]
        }
      ],
      "source": [
        "# Function to read the data\n",
        "def read_data(filename):\n",
        "    data = pd.read_csv(filename)\n",
        "\n",
        "    # Extract features\n",
        "    features = data.iloc[:,1 :-1].values\n",
        "\n",
        "    # Extract and encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    data.iloc[:, -1] = label_encoder.fit_transform(data.iloc[:, -1])\n",
        "    labels = data.iloc[:, -1].values\n",
        "\n",
        "    return features, labels\n",
        "# Read the data\n",
        "data_url = \"https://raw.githubusercontent.com/hassanaljaber/Data-IoT/main/data_yousef.csv\" # enter your data URL or PATH here in enclosed in \" \" IF YOUR NOTEBOOK IS IN THE SAME FOLDER AS data.csv, which is your data you downloaded, then this will run as it is.\n",
        "                    # otherwise, you have to specify a different path or url\n",
        "x, y = read_data(data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "3eb86201",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eb86201",
        "outputId": "b94a8dc4-ebb3-4d63-c20b-39b518d13e65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80590, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "x.shape ### IN THE FOLLOWING PARTS OF THE CODE, MAKE SURE THAT EVERYTING IS LOADED CORRECTLY, YOU SHOULD HAVE A DATASET WITH 22 CLASSES, (n-rows, 6 columns, later another dimension will be added here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "6b640bf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b640bf8",
        "outputId": "56d77072-1aa2-4635-da7a-b8747c2b736d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80590,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9650592c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9650592c",
        "outputId": "63e6f769-6b97-4d69-e098-14d5b98f52f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "np.unique(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0edc69b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0edc69b6",
        "outputId": "d562c5fc-ff7b-4d1a-fafe-973d0e015d54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 60.70153 ,   3.478926, -12.537908,   0.82506 ,   0.8963  ,\n",
              "        -0.344533])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b4eec323",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4eec323",
        "outputId": "07952ee6-46c2-44f2-ee6d-1c2c39b5d88b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "y[0] # these were sample rows from the data for your to inspect, you should see a 6 by 1 vector above and a single value here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "9db6440b",
      "metadata": {
        "id": "9db6440b"
      },
      "outputs": [],
      "source": [
        "# Split the data into training, validation, and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "0b135163",
      "metadata": {
        "id": "0b135163"
      },
      "outputs": [],
      "source": [
        "# Reshape the data\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "936243fe",
      "metadata": {
        "id": "936243fe"
      },
      "outputs": [],
      "source": [
        "# Determine the input shape and number of classes\n",
        "input_shape = (x_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "4cb2989e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cb2989e",
        "outputId": "7f1b39e2-55fc-43a6-995b-06e74a466ed6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "num_classes # must have 22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "26c6890e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26c6890e",
        "outputId": "e01ec9cf-7fbb-47dc-9dcb-bd4ff6bf6f6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "859aa647",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "859aa647",
        "outputId": "ffe5a3c2-2d4c-4b8a-9e5c-4460b660227b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58024, 6, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "eab565dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eab565dd",
        "outputId": "edf092e4-8feb-4096-a212-a9885bc88d73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58024,)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ab950213",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab950213",
        "outputId": "e192ed2b-f0b5-4e25-acb4-f0f2c394ab52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.05572590e+01],\n",
              "       [-2.39156280e+01],\n",
              "       [-1.79886032e+02],\n",
              "       [ 1.07236000e+00],\n",
              "       [ 1.38438800e+00],\n",
              "       [ 1.14208000e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "7f11432f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f11432f",
        "outputId": "642dda7b-169a-4b57-8580-0b944a4e109a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "cd51204b",
      "metadata": {
        "id": "cd51204b"
      },
      "outputs": [],
      "source": [
        "# Transformer Encoder function with dropout and L2 regularization\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.1, l2_reg=0.01):\n",
        "\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed-forward network with dropout and L2 regularization\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(inputs.shape[-1], activation = 'softmax')(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return x + res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "9df843aa",
      "metadata": {
        "id": "9df843aa"
      },
      "outputs": [],
      "source": [
        "# Transformer Decoder function\n",
        "def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0.1, l2_reg=0.01):\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(res, enc_outputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = x + res\n",
        "\n",
        "    # Feed-forward network\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    '''\n",
        "    YOU MAY WANT TO ADD OR REMOVE THESE TWO LINES HERE PRECISELY IN THIS PART OF THE CODE, PAY ATTENTION TO THE INDENTATION, PYTHON REQUIRES CONSISTENCY IN ORDER FOR THE CODE TO RUN CORRECTLY\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    '''\n",
        "\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(inputs.shape[-1], activation = 'softmax')(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return x + res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "d9851305",
      "metadata": {
        "id": "d9851305"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0, l2_reg=0):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Encoder\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout, l2_reg)\n",
        "\n",
        "\n",
        "    # Decoder\n",
        "    decoder_input = keras.Input(shape=input_shape)\n",
        "    dec = decoder_input\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        dec = transformer_decoder(dec, x, head_size, num_heads, ff_dim, dropout, l2_reg)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    dec = layers.Flatten()(dec)\n",
        "    x = layers.Concatenate()([x, dec])\n",
        "\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model([inputs, decoder_input], outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "1d648db6",
      "metadata": {
        "id": "1d648db6"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters\n",
        "\"\"\"\n",
        "# THIS IS THE PART YOU SHOULD PLAY AROUND WITH\n",
        "# YOU MAY REDUCE THESE NUMBERS IF YOUR MACHINE IS OTHERWISE INCAPABLE OF RUNNING THE CODE\"\"\"\n",
        "\n",
        "head_size = 4\n",
        "num_heads = 4\n",
        "ff_dim = 256\n",
        "num_transformer_blocks = 4\n",
        "mlp_units = [256]\n",
        "dropout = 0.1\n",
        "mlp_dropout = 0.1\n",
        "initial_lr = 0.001\n",
        "l2_reg=0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "6c794103",
      "metadata": {
        "id": "6c794103"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "64e4c3ef",
      "metadata": {
        "id": "64e4c3ef"
      },
      "outputs": [],
      "source": [
        "# Create the optimizer with the initial learning rate\n",
        "optimizer = Adam(learning_rate=initial_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "0e19e795",
      "metadata": {
        "id": "0e19e795"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "02a51f0f",
      "metadata": {
        "id": "02a51f0f"
      },
      "outputs": [],
      "source": [
        "# Create the ReduceLROnPlateau callback\n",
        "lr_callback = ReduceLROnPlateau(factor=0.1, patience=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "511f6219",
      "metadata": {
        "id": "511f6219"
      },
      "outputs": [],
      "source": [
        "# Record the start time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "19d80153",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19d80153",
        "outputId": "281f2dcc-c32d-4aaa-ee46-2eb9f3091cab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "907/907 [==============================] - 88s 63ms/step - loss: 2.9435 - accuracy: 0.3836 - val_loss: 1.1078 - val_accuracy: 0.6064 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "907/907 [==============================] - 57s 63ms/step - loss: 1.1024 - accuracy: 0.6090 - val_loss: 0.7909 - val_accuracy: 0.7186 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "907/907 [==============================] - 55s 60ms/step - loss: 0.7893 - accuracy: 0.7148 - val_loss: 0.6087 - val_accuracy: 0.7647 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.6221 - accuracy: 0.7662 - val_loss: 0.5335 - val_accuracy: 0.8112 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.5430 - accuracy: 0.7907 - val_loss: 0.4772 - val_accuracy: 0.7983 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.4930 - accuracy: 0.8071 - val_loss: 0.3825 - val_accuracy: 0.8586 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.4588 - accuracy: 0.8198 - val_loss: 0.3790 - val_accuracy: 0.8472 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.4261 - accuracy: 0.8320 - val_loss: 0.3475 - val_accuracy: 0.8676 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.4059 - accuracy: 0.8412 - val_loss: 0.3330 - val_accuracy: 0.8618 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.3837 - accuracy: 0.8490 - val_loss: 0.3506 - val_accuracy: 0.8446 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "907/907 [==============================] - 56s 61ms/step - loss: 0.3733 - accuracy: 0.8516 - val_loss: 0.3072 - val_accuracy: 0.8811 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.3536 - accuracy: 0.8586 - val_loss: 0.3132 - val_accuracy: 0.8790 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.3473 - accuracy: 0.8628 - val_loss: 0.3462 - val_accuracy: 0.8688 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.3351 - accuracy: 0.8663 - val_loss: 0.3053 - val_accuracy: 0.8710 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.3232 - accuracy: 0.8738 - val_loss: 0.2990 - val_accuracy: 0.8916 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.3222 - accuracy: 0.8748 - val_loss: 0.3016 - val_accuracy: 0.8967 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.3082 - accuracy: 0.8786 - val_loss: 0.2879 - val_accuracy: 0.8901 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.3028 - accuracy: 0.8798 - val_loss: 0.2539 - val_accuracy: 0.9051 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.3047 - accuracy: 0.8801 - val_loss: 0.3311 - val_accuracy: 0.8775 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "907/907 [==============================] - 57s 63ms/step - loss: 0.3003 - accuracy: 0.8832 - val_loss: 0.2396 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2932 - accuracy: 0.8861 - val_loss: 0.2395 - val_accuracy: 0.9055 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2895 - accuracy: 0.8871 - val_loss: 0.2516 - val_accuracy: 0.8979 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "907/907 [==============================] - 56s 62ms/step - loss: 0.2778 - accuracy: 0.8906 - val_loss: 0.2503 - val_accuracy: 0.9064 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2778 - accuracy: 0.8916 - val_loss: 0.2248 - val_accuracy: 0.9198 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "907/907 [==============================] - 54s 59ms/step - loss: 0.2776 - accuracy: 0.8919 - val_loss: 0.2015 - val_accuracy: 0.9208 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2679 - accuracy: 0.8956 - val_loss: 0.2112 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "907/907 [==============================] - 56s 62ms/step - loss: 0.2796 - accuracy: 0.8926 - val_loss: 0.2126 - val_accuracy: 0.9142 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2756 - accuracy: 0.8951 - val_loss: 0.2133 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "907/907 [==============================] - 55s 60ms/step - loss: 0.2742 - accuracy: 0.8953 - val_loss: 0.2069 - val_accuracy: 0.9157 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "907/907 [==============================] - 54s 59ms/step - loss: 0.2614 - accuracy: 0.8995 - val_loss: 0.2494 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2587 - accuracy: 0.8986 - val_loss: 0.2066 - val_accuracy: 0.9182 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2620 - accuracy: 0.8992 - val_loss: 0.2331 - val_accuracy: 0.9117 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2615 - accuracy: 0.8993 - val_loss: 0.1938 - val_accuracy: 0.9269 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2553 - accuracy: 0.9018 - val_loss: 0.2301 - val_accuracy: 0.9098 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2539 - accuracy: 0.9024 - val_loss: 0.1864 - val_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2646 - accuracy: 0.8997 - val_loss: 0.2255 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.2589 - accuracy: 0.9000 - val_loss: 0.1873 - val_accuracy: 0.9336 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "907/907 [==============================] - 50s 56ms/step - loss: 0.2528 - accuracy: 0.9031 - val_loss: 0.1856 - val_accuracy: 0.9258 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2555 - accuracy: 0.9025 - val_loss: 0.2006 - val_accuracy: 0.9249 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.2444 - accuracy: 0.9067 - val_loss: 0.2121 - val_accuracy: 0.9067 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2519 - accuracy: 0.9030 - val_loss: 0.1977 - val_accuracy: 0.9266 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2402 - accuracy: 0.9082 - val_loss: 0.2647 - val_accuracy: 0.8932 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2501 - accuracy: 0.9048 - val_loss: 0.2299 - val_accuracy: 0.9075 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2434 - accuracy: 0.9068 - val_loss: 0.2063 - val_accuracy: 0.9166 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "907/907 [==============================] - 50s 55ms/step - loss: 0.2426 - accuracy: 0.9077 - val_loss: 0.1952 - val_accuracy: 0.9202 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "907/907 [==============================] - 54s 59ms/step - loss: 0.2417 - accuracy: 0.9077 - val_loss: 0.1982 - val_accuracy: 0.9224 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2454 - accuracy: 0.9057 - val_loss: 0.2196 - val_accuracy: 0.9138 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "907/907 [==============================] - 51s 56ms/step - loss: 0.2416 - accuracy: 0.9090 - val_loss: 0.2032 - val_accuracy: 0.9268 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2301 - accuracy: 0.9126 - val_loss: 0.1862 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2386 - accuracy: 0.9095 - val_loss: 0.1749 - val_accuracy: 0.9338 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "907/907 [==============================] - 54s 59ms/step - loss: 0.2315 - accuracy: 0.9107 - val_loss: 0.2059 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.2375 - accuracy: 0.9093 - val_loss: 0.1944 - val_accuracy: 0.9223 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2450 - accuracy: 0.9066 - val_loss: 0.2004 - val_accuracy: 0.9225 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2365 - accuracy: 0.9095 - val_loss: 0.2079 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2279 - accuracy: 0.9119 - val_loss: 0.2468 - val_accuracy: 0.8971 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2314 - accuracy: 0.9119 - val_loss: 0.1882 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2353 - accuracy: 0.9104 - val_loss: 0.1676 - val_accuracy: 0.9359 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2332 - accuracy: 0.9110 - val_loss: 0.1914 - val_accuracy: 0.9271 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2337 - accuracy: 0.9121 - val_loss: 0.2321 - val_accuracy: 0.9085 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2316 - accuracy: 0.9122 - val_loss: 0.1775 - val_accuracy: 0.9309 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "907/907 [==============================] - 54s 59ms/step - loss: 0.2304 - accuracy: 0.9119 - val_loss: 0.2011 - val_accuracy: 0.9210 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.2285 - accuracy: 0.9128 - val_loss: 0.1943 - val_accuracy: 0.9196 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2317 - accuracy: 0.9116 - val_loss: 0.1606 - val_accuracy: 0.9417 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "907/907 [==============================] - 55s 60ms/step - loss: 0.2343 - accuracy: 0.9110 - val_loss: 0.1726 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2287 - accuracy: 0.9139 - val_loss: 0.2313 - val_accuracy: 0.8969 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2301 - accuracy: 0.9133 - val_loss: 0.1850 - val_accuracy: 0.9303 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2244 - accuracy: 0.9155 - val_loss: 0.1754 - val_accuracy: 0.9324 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.2203 - accuracy: 0.9158 - val_loss: 0.1696 - val_accuracy: 0.9383 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2320 - accuracy: 0.9136 - val_loss: 0.1914 - val_accuracy: 0.9243 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2203 - accuracy: 0.9169 - val_loss: 0.1833 - val_accuracy: 0.9272 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "907/907 [==============================] - 55s 61ms/step - loss: 0.2204 - accuracy: 0.9157 - val_loss: 0.1893 - val_accuracy: 0.9271 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "907/907 [==============================] - 52s 58ms/step - loss: 0.2193 - accuracy: 0.9174 - val_loss: 0.1935 - val_accuracy: 0.9245 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2226 - accuracy: 0.9156 - val_loss: 0.1670 - val_accuracy: 0.9355 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2307 - accuracy: 0.9150 - val_loss: 0.1971 - val_accuracy: 0.9220 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "907/907 [==============================] - 55s 61ms/step - loss: 0.2240 - accuracy: 0.9156 - val_loss: 0.1853 - val_accuracy: 0.9347 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "907/907 [==============================] - 51s 57ms/step - loss: 0.2236 - accuracy: 0.9171 - val_loss: 0.1767 - val_accuracy: 0.9398 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2169 - accuracy: 0.9183 - val_loss: 0.1623 - val_accuracy: 0.9367 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "907/907 [==============================] - 58s 64ms/step - loss: 0.2163 - accuracy: 0.9192 - val_loss: 0.2285 - val_accuracy: 0.9116 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2269 - accuracy: 0.9158 - val_loss: 0.2089 - val_accuracy: 0.9174 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.2201 - accuracy: 0.9165 - val_loss: 0.1532 - val_accuracy: 0.9373 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2171 - accuracy: 0.9183 - val_loss: 0.1813 - val_accuracy: 0.9302 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "907/907 [==============================] - 54s 59ms/step - loss: 0.2137 - accuracy: 0.9197 - val_loss: 0.1894 - val_accuracy: 0.9296 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2230 - accuracy: 0.9162 - val_loss: 0.1897 - val_accuracy: 0.9289 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "907/907 [==============================] - 55s 60ms/step - loss: 0.2126 - accuracy: 0.9192 - val_loss: 0.1651 - val_accuracy: 0.9420 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "907/907 [==============================] - 54s 59ms/step - loss: 0.2221 - accuracy: 0.9157 - val_loss: 0.1930 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "907/907 [==============================] - 54s 59ms/step - loss: 0.2161 - accuracy: 0.9191 - val_loss: 0.1982 - val_accuracy: 0.9333 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "907/907 [==============================] - 58s 64ms/step - loss: 0.2165 - accuracy: 0.9196 - val_loss: 0.1835 - val_accuracy: 0.9339 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "907/907 [==============================] - 55s 60ms/step - loss: 0.2124 - accuracy: 0.9197 - val_loss: 0.1781 - val_accuracy: 0.9288 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "907/907 [==============================] - 61s 68ms/step - loss: 0.2160 - accuracy: 0.9190 - val_loss: 0.1825 - val_accuracy: 0.9345 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "907/907 [==============================] - 56s 62ms/step - loss: 0.2161 - accuracy: 0.9191 - val_loss: 0.1946 - val_accuracy: 0.9276 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "907/907 [==============================] - 57s 63ms/step - loss: 0.2178 - accuracy: 0.9179 - val_loss: 0.1571 - val_accuracy: 0.9387 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.2207 - accuracy: 0.9183 - val_loss: 0.2094 - val_accuracy: 0.9211 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2215 - accuracy: 0.9181 - val_loss: 0.2154 - val_accuracy: 0.9185 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2220 - accuracy: 0.9185 - val_loss: 0.1868 - val_accuracy: 0.9325 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "907/907 [==============================] - 53s 59ms/step - loss: 0.2074 - accuracy: 0.9218 - val_loss: 0.1855 - val_accuracy: 0.9350 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "907/907 [==============================] - 55s 61ms/step - loss: 0.2123 - accuracy: 0.9205 - val_loss: 0.1754 - val_accuracy: 0.9332 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "907/907 [==============================] - 52s 57ms/step - loss: 0.2161 - accuracy: 0.9191 - val_loss: 0.1545 - val_accuracy: 0.9420 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "907/907 [==============================] - 53s 58ms/step - loss: 0.2129 - accuracy: 0.9194 - val_loss: 0.1548 - val_accuracy: 0.9433 - lr: 0.0010\n",
            "Epoch 99/100\n",
            "907/907 [==============================] - 54s 60ms/step - loss: 0.2227 - accuracy: 0.9162 - val_loss: 0.1693 - val_accuracy: 0.9364 - lr: 0.0010\n",
            "Epoch 100/100\n",
            "907/907 [==============================] - 57s 63ms/step - loss: 0.2133 - accuracy: 0.9215 - val_loss: 0.1764 - val_accuracy: 0.9278 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x797c508551b0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "model.fit([x_train, x_train], y_train,\n",
        "          batch_size=64,\n",
        "          epochs=100,\n",
        "          validation_data=([x_val, x_val], y_val),\n",
        "          callbacks=[lr_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "3ffe7d0c",
      "metadata": {
        "id": "3ffe7d0c"
      },
      "outputs": [],
      "source": [
        "# Record the end time\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "e8dd9c65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8dd9c65",
        "outputId": "13d0d644-73a5-41e0-929e-8d2543dc14cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Running Time: 5390.62 seconds\n"
          ]
        }
      ],
      "source": [
        "# Calculate the total running time\n",
        "running_time = end_time - start_time\n",
        "print(\"Total Running Time: {:.2f} seconds\".format(running_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "23ebca14",
      "metadata": {
        "id": "23ebca14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adff9167-da4d-46a7-e69c-d9b3565c75c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252/252 [==============================] - 4s 15ms/step - loss: 0.1818 - accuracy: 0.9269\n",
            "Test loss: 0.18181559443473816, Test accuracy: 0.9269140362739563\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([x_test, x_test], y_test)\n",
        "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "78f8e19d",
      "metadata": {
        "id": "78f8e19d"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save(\"my_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}